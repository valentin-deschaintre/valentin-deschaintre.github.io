---
layout: cvmp-default
title: Keynotes
year: 2021
---

We are pleased to announce the following keynote speakers for CVMP 2021:


<a name="CO" />
<div class="row">
<div class="col-xs-12 col-sm-7 col-md-8 col-lg-9" markdown="1" style="text-align: justify">

#### Cengiz Öztireli, University of Cambridge <br> 3D Digital Reality – Modeling for Perception

Creating digital models of reality is one of the grand challenges of computer science. In this talk, I will summarize some of our efforts towards achieving this goal to allow machines to perceive the world as well as and beyond humans. The focus will be on capturing and replicating the visual world and techniques at the intersection of computer graphics, vision, and machine learning to solve several fundamental problems and their practical applications.

*Cengiz Öztireli is an Associate Professor at the University of Cambridge and a Senior Researcher at Google. He previously worked as a Research Scientist at Disney Research, and as a Senior Research Associate at ETH Zürich. He obtained his M.S. and Ph.D. degrees in computer science from ETH (jointly funded by the Swiss National Science Foundation) and completed a double major in computer and electronics engineering at Koç University (summa cum laude, valedictorian). He has been honored with several awards including the Eurographics Best Ph.D. Thesis Award, Fulbright Science and Technology Award, and the UKRI Future Leaders Fellowship.*

</div>

<figure class="col-xs-6 col-sm-5 col-md-4 col-lg-3">
  <img src="{{site.url}}/img/2021/keynotes/CengizOztireli.jpg" class="img-responsive img-thumbnail" alt="Cengiz Öztireli" title="Cengiz Öztireli">
</figure>

</div>


<a name="DC" />
<div class="row">
<div class="col-xs-12 col-sm-7 col-md-8 col-lg-9" markdown="1" style="text-align: justify">

#### Darren Cosker, Microsoft <br> Creating Presence in Mixed Reality and the Metaverse

Imagine being able to have a conversation with someone who is hundreds of miles away, but it feels like they are actually there. Technology which can achieve this would change society - bringing distant family and friends closer together, transforming the way we work and reducing carbon footprints. However, creating compelling interactive experiences involving other people in mixed reality and the metaverse is a challenging task combining expertise in computer vision, graphics, AI and engineering. In this talk I will examine some of the technologies required to make this a reality and the challenges ahead.

*Darren Cosker is a Scientist at Microsoft's Mixed Reality and AI laboratory (Cambridge), and holds a part time full Professor position at the University of Bath. He was previously the founding Director of CAMERA (2015-2021) - a multi-disciplinary research centre based dedicated to understanding and modeling human motion and appearance. At Microsoft Darren is helping realise the vision of 'presence' in mixed reality and the metaverse through products such as Microsoft Mesh. Prior to joining Microsoft Darren held personal research fellowships from the Royal Society (2012-2016) and the Royal Academy of Engineering (2007-2012).*

</div>

<figure class="col-xs-6 col-sm-5 col-md-4 col-lg-3">
  <img src="{{site.url}}/img/2021/keynotes/DarrenCosker.jpg" class="img-responsive img-thumbnail" alt="Darren Cosker" title="Darren Cosker">
</figure>

</div>


<a name="ST" />
<div class="row">
<div class="col-xs-12 col-sm-7 col-md-8 col-lg-9" markdown="1" style="text-align: justify">

#### Siyu Tang, ETH Zürich <br> Learning to Capture and Synthesise 3D Humans in 3D Scene

In recent years, many high-quality datasets of 3D indoor scenes have emerged such as Replica and Gibson, which employ 3D scanning and reconstruction technologies to create digital 3D environments. Also, virtual robotic agents exist inside of 3D environments such as the Habitat simulator. These are used to develop scene understanding methods from embodied views, thus providing platforms for indoor robot navigation, AR/VR and many other applications. Despite this progress, a significant limitation of these environments is that they do not contain people. The reason such worlds contain no people is that there are no fully automated tools to synthesise realistic people interacting with 3D scenes naturally, and manually doing this requires significant artist effort. In this talk, I will present our previous and ongoing research about capture and synthesis of realistic people interacting realistically with 3D scenes and objects.

*Siyu Tang is an assistant professor at ETH Zürich in the Department of Computer Science since January 2020. She received an early career research grant to start her own research group at the Max Planck Institute for Intelligent Systems in November 2017. She was a postdoctoral researcher in the same institute, advised by Dr. Michael Black. She finished her PhD at the Max Planck Institute for Informatics and Saarland University in 2017, under the supervision of Professor Bernt Schiele. Before that, she received her Master’s degree in Media Informatics at RWTH Aachen University, advised by Prof. Bastian Leibe and her Bachelor degree in Computer Science at Zhejiang University, China. She has received several awards for her research, including the Best Paper Award at BMVC 2012 and 3DV 2020, Best Paper Award Candidates at CVPR 2021, an ELLIS PhD Award and a DAGM-MVTec Dissertation Award.*

</div>

<figure class="col-xs-6 col-sm-5 col-md-4 col-lg-3">
  <img src="{{site.url}}/img/2021/keynotes/SiyuTang-800.jpg" class="img-responsive img-thumbnail" alt="Siyu Tang" title="Siyu Tang">
</figure>

</div>


<a name="TR" />
<div class="row">
<div class="col-xs-12 col-sm-7 col-md-8 col-lg-9" markdown="1" style="text-align: justify">

#### Tobias Ritschel, University College London <br> Perceptually-inspired VR Image Synthesis

Images shown on future near-eye displays will be perceived differently. In this talk I will argue that, hence, all image synthesis itself will need to change. I will mostly discuss means to reduce bandwidth and/or latency. This can be achieved by rendering images that are perceived like other images directly (Ventral Metamers), by changing how the deepest internals of graphics hardware work (Perceptual Rasterization) or by switching to a domain different from pixels (Laplacian).

*Professor Tobias Ritschel has received his PhD from Saarland University (MPI) in 2009. He was a post-doctoral researcher at Telecom ParisTech / CNRS 2009-10 and a Senior Researcher at MPI 2010-15. Tobias was appointed Senior Lecturer at University College London in 2015 where he was named Full Professor of Computer Graphics in 2019. His work has received the EG Dissertation (2010) and Young Researcher Award (2014). His interests include Image Synthesis and Human Visual Perception, now frequently including applied AI.*

</div>

<figure class="col-xs-6 col-sm-5 col-md-4 col-lg-3">
  <img src="{{site.url}}/img/2021/keynotes/TobiasRitschel.jpg" class="img-responsive img-thumbnail" alt="Tobias Ritschel" title="Tobias Ritschel">
</figure>

</div>
