---
layout: cvmp-default
title: Conference Programme
year: 2021
---

{% include_relative covid-19.md %}

### Tentative Programme ###

<div class="col-12 col-sm-12 col-lg-12">
	<a name="monday"></a>
	<div class="panel panel-default">
		<div class="panel-heading"><b>Monday 6th December 2021</b></div>
		<table class="table table-striped">
			<tr>
				<td>09:00</td>
				<td><b>Registration opens with Coffee</b></td>
			</tr>
			<tr>
				<td>09:30</td>
				<td><b>Chairs’ Welcome</b><br/>Rafał Mantiuk, <i>University of Cambridge</i> and Christian Richardt, <i>University of Bath</i> (Conference Chairs)</td>
			</tr>
			<tr>
				<td>09:40</td>
				<td><b>Papers and Industry Talks Session 1: Bring on the colours!</b><br/><!--<i>To be confirmed (Chair)</i><br/>-->
					<ul>
						<li>Semantic-driven Colorization<br/><i>Man M. Ho (Hosei University), Lu Zhang (INSA Rennes), Alexander Raake (TU Ilmenau), Jinjia Zhou (Hosei University)</i></li>
						<li>Arnold 7 update<br/><i>Frederic Servant (Autodesk)</i></li>
						<li>Photometric Stereo with Area Lights for Lambertian Surfaces<br/><i>Jiangbin Gan (University of Marburg), Thorsten Thormählen (University of Marburg)</i></li>
						<li>Material acquisition and editing<br/><i>Valentin Deschaintre (Adobe Research)</i></li>
					</ul>
				</td>
			</tr>
			<tr>
				<td>11:00</td>
				<td><b>Coffee Break</b><br/><i>Poster presenters put up posters</i></td>
			</tr>	
			<tr>
				<td>11:30</td>
				<td><a href="/2021/keynotes/#CO"><b>Keynote: 3D Digital Reality – Modeling for Perception</b></a><br/>Cengiz Öztireli, <i>University of Cambridge</i></td>
			</tr>
			<tr>
				<td>12:30</td>
				<td><b>Spotlight Session</b><br/>
					<ul>
						<li>One-shot SVBRDF Estimation Including Anisotropic Material<br/><i>Nozomu Terada (Tokyo University of Agriculture and Technology), Ikuko Shimizu (Tokyo University of Agriculture and Technology)</i></li>
						<li>AURealnessGAN - An Architecture that Enables Manipulation of FACS Action Units in Face Image Generation<br/><i>Koyo Ishihara (Tokyo University of Agriculture and Technology), Ikuko Shimizu (Tokyo University of Agriculture and Technology), Akio Sashima (National Institute of Advanced Industrial Science and Technology), Koichi Kurumatani (National Institute of Advanced Industrial Science and Technology)</i></li>
						<li>Learning semantic object segmentation for video post-production<br/><i>Flavien Jourdren (InterDigital), Emmanuel Jolly (InterDigital R&D France), Claire-Helene Demarty (Technicolor), Frederic Lefebvre (InterDigital), Pierre Hellier (InterDigital (Technicolor))</i></li>
						<li>A Deep Learning Based Approach for Camera Switching in Amateur Ice Hockey Game Broadcasting<br/><i>Hamid Reza Tohidypour (University of British Columbia), Yixiao Wang (University of British Columbia), Mohsen Gholami (University of British Columbia), Megha Kalia (University of British Columbia), Kexin Wen (University of British Columbia), Lawrence Li (University of British Columbia), Panos Nasiopoulos (University of British Columbia), Mahsa Pourazad (TELUS Communications Inc.)</i></li>
						<li>A Step Towards Automating the Synthesis of a Scene Script<br/><i>Américo Pereira (INESC TEC), Ricardo Carvalho (FEUP), Pedro Carvalho (INESC TEC and Universidade do Porto), Luís Corte-Real (FEUP)</i></li>
						<li>Look-Up-Table Mystified<br/><i>Jurgen Stauder (InterDigital), Patrick Morvan (InterDigital), Angelo Mazzante (InterDigital), Anita Orhand (InterDigital), John Frith (MPC)</i></li>
						<li>Spatio-temporal algorithm for 3D sequences noise reduction<br/><i>Ljubomir Jovanov (UGent)</i></li>
						<li>Image Super-Resolution via Hierarchical Attention-Based Multi-References Sampling<br/><i>Marco Pesavento (University of Surrey), Marco Volino (University of Surrey), Adrian Hilton (University of Surrey)</i></li>
						<li>Human Point Cloud Generation using Deep Learning<br/><i>Ryan Spick (University of York)</i></li>
						<li>Demo: Video Provenance Network for Robust Content Attribution<br/><i>Alexander Black (University of Surrey), Tu Bui (University of Surrey), Simon Jenni (Adobe Research), Viswanathan (Vishy) Swaminathan (Adobe), John Collomosse (Adobe Research)</i></li>
					</ul>
				</td>
			</tr>
			<tr>
				<td>12:40</td>
				<td><b>Lunch, Demo and Short Papers</b></td>
			</tr>
			<tr>
				<td>14:30</td>
				<td><b>Industry Special Session on Digital Humans</b><br/>
					<ul>
						<li>Volumetric video at the intersection of visual effects and virtual production<br/><i>Juraj Tomori (dimension), Charles Dupont (dimension), George Ash (dimension), Mike Pelton (dimension)</i></li>
						<li>High-Performance Multi-Camera Systems for Volumetric Capture and 4D Face/Body Scanning<br/><i>Andrew Searle (IO Industries Inc)</i></li>
						<li>The Creation of 3D Human Datasets for CV Research<br/><i>Lukas Lamprecht (Renderpeople)</i></li>						
					</ul>
				</td>
			</tr>		
			<tr>
				<td>15:30</td>
				<td><b>Posters Session (coffee served)</b></td>
			</tr>	
			<tr>
				<td>16:00</td>
				<td><a href="/2021/keynotes/#DC"><b>Keynote: Creating Presence in Mixed Reality and the Metaverse</b></a><br/>Darren Cosker, <i>Microsoft</i></td>
			</tr>
			<tr>
				<td>17:00</td>
				<td><b>Networking Reception</b></td>
			</tr>
		</table>
	</div>
	<a name="tuesday"></a>
	<div class="panel panel-default">
		<div class="panel-heading"><b>Tuesday 7th December 2021</b></div>
		<table class="table table-striped">
			<tr>
				<td>09:00</td>
				<td><b>Registration opens with Coffee</b></td>
			</tr>
			<tr>
				<td>09:30</td>
				<td><b>Papers and Industry Talks Session 2: And action!</b><br/>
					<ul>
						<li>Automatic Camera Control and Directing with an Ultra-High-Definition Collaborative Recording System<br/><i>Bram Vanherle (Hasselt University), Tim Vervoort (Hasselt University), Nick Michiels (Hasselt University), Philippe Bekaert (Hasselt University)</i></li>
						<li>Contact-rich simulation in NVIDIA Omniverse<br/><i>Kier Storey and Michelle Lu (NVIDIA)</i></li>
						<li>FacialFilmroll: High-resolution multi-shot video editing<br/><i>Bharath Bhushan Damodaran (InterDigital R&D), Emmanuel Jolly (InterDigital R&D France), Gilles Puy (In his own name), Philippe-Henri Gosselin (InterDigital), Cédric Thébault (InterDigital), Junghyun Ahn (InterDigital), Tim Christensen (In his own name), Paul Ghezzo (In his own name), Pierre Hellier (InterDigital (Technicolor))</i></li>
						<li>Foundry and Machine Learning<br/><i>Ben Kent (Foundry)</i></li>
					</ul>
				</td>
			</tr>
			<tr>
				<td>10:50</td>
				<td><b>Coffee Break</b><br/><i>Poster presenters put up posters</i></td>
			</tr>	
			<tr>
				<td>11:20</td><td><a href="/2021/keynotes/#ST"><b>Keynote: Learning to Capture and Synthesise 3D Humans in 3D Scene</b></a><br/>Siyu Tang, <i>ETH Zürich</i></td>
			</tr>
			<tr>
				<td>12:20</td>
				<td><b>Lunch, Demo and Short Papers</b></td>
			</tr>
			<tr>
				<td>14:00</td>
				<td><b>Papers and Industry Talks Session 3: Gimme the data!</b><br/>
					<ul>
						<li>Depth Estimation from a Single Omnidirectional Image using Domain Adaptation<br/><i>Yihong Wu (The University of Southampton ECS VLC Group), Yuwen Heng (University of Southampton), Mahesan Niranjan (University of Southampton), Hansung Kim (University Of Southampton)</i></li>
						<li>VPN: Video Provenance Network for Robust Content Attribution<br/><i>Alexander Black (University of Surrey), Tu Bui (University of Surrey), Simon Jenni (Adobe Research), Viswanathan (Vishy) Swaminathan (Adobe), John Collomosse (Adobe Research)</i></li>
						<li>High-fidelity procedural data synthesis for validation and training of perception function<br/><i>Oliver Grau (Intel), Korbinian Hagn (Intel)</i></li>
						<li>Speech-Driven Conversational Agents using Conditional Flow-VAEs<br/><i>Sarah Taylor (University of East Anglia), Jonathan Windle (University of East Anglia), David Greenwood (University of East Anglia), Iain Matthews (Carnegie Mellon University)</i></li>
					</ul>
				</td>
			</tr>
			<tr>
				<td>15:20</td>
				<td><b>Posters Session (coffee served)</b></td>
			</tr>
			<tr>
				<td>15:50</td>
				<td><a href="/2021/keynotes/#TR"><b>Keynote: Perceptually-inspired VR Image Synthesis</b></a><br/>Tobias Ritschel, <i>University College London</i></td>
			</tr>
			<tr>
				<td>16:50</td>
				<td><b>Prizes, Announcements and Close</b></td>
			</tr>
		</table>
	</div>
</div>
